<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="python网络数据采集, xxxxlc">
    <meta name="description" content="Write Freely ">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>python网络数据采集 | xxxxlc</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="alternate" href="/atom.xml" title="xxxxlc" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd0d86b5f-b9b4-4ddd-b9dc-0c3355bbda7a%2FUntitled.png?table=block&id=4353d6b8-1b19-430d-9e1d-c4f9ccbd1c4f&spaceId=131ec741-5489-4e80-ba4f-492ddc0cf4aa&width=2000&userId=7acf2237-28fc-4c4c-8cb8-0a011d9d4000&cache=v2);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    


    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">xxxxlc</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">xxxxlc</div>
        <div class="logo-desc">
            
            Write Freely 
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/xxxxlc/xxxxlc.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #a7269c;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/xxxxlc/xxxxlc.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">python网络数据采集</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        /* width: 345px;
        padding-left: 20px; */
        width: 345px;
        padding-left: 20px;
        background-color: rgba(63, 50, 182, 0.7);
        border-radius: 20px;
        box-shadow: 0 10px 35px 2px rgba(31, 22, 153, 0.15), 0 5px 15px rgba(46, 187, 27, 0.07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/reading-note/">
                                <span class="chip bg-color">reading note</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-09-10
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="chapter-1-初见网络爬虫">Chapter 1 初见网络爬虫</h1>
<h2 id="网络连接">1 网络连接</h2>
<p>python通过urlopen模块进行数据交换</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen

html = urlopen('url')
print(html.read())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>urllib</strong>是一个包，它收集了以下几个用于处理<strong>url</strong>的模块：</p>
<ul>
<li><strong>urllib.request</strong> 主要用于打开和读取<strong>URLs</strong></li>
<li><strong>urllib.error</strong> 包含了由<strong>urllib.request</strong>引发的异常</li>
<li><strong>urllib.parse</strong> 用于解析<strong>URLs</strong></li>
<li><strong>urllib.robotparesr</strong> 用于解析<strong>robot.txt</strong>文件</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>data</strong> 必须是一个对象，指定要发送到服务器的附加数据，如果不需要此类数据，则为 <strong>None</strong>。</p>
<p>其余见<strong>urllib.request</strong>文档：<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request">urllib.request — Extensible library for opening URLs — Python 3.9.6 documentation</a></p>
<p><strong>urllib.error</strong> 通常包含三个异常类：<strong>URLError</strong> 、<strong>HTPPError</strong> 、<strong>ContentTooShortError(msg, content)</strong></p>
<ul>
<li><strong>URLError</strong> 通常的错误</li>
<li><strong>HTPPError</strong> url打不开或者服务器不存在</li>
<li><strong>ContentTooShortError</strong> 下载量小于预期量时会发生的错误</li>
</ul>
<h2 id="beautifulsoup">2 BeautifulSoup</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from bs4 import BeautifulSoup<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>导入<strong>BeautifulSoup</strong>，此模块相当于可以将<strong>urllib.request</strong>获取的代码按照标签进行分类，得到如下图所示的效果：</p>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210829085925876.png" alt="image-20210829085925876"><figcaption aria-hidden="true">image-20210829085925876</figcaption>
</figure>
<p>然后根据对象的标签的名称就可以进行查找与索引，比如要输出<strong>html</strong>的<strong>h1</strong>：</p>
<p><strong>bs.h1</strong> 、<strong>bs.html.body.h1</strong> 、<strong>bs.body.h1</strong> 、<strong>bs.html.h1</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://www.pythonscraping.com/pages/page1.html')
bs = BeautifulSoup(html.read(), 'html.parser')
print(bs.h1)
print(bs.html.body.h1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="网络连接的异常">3 网络连接的异常</h2>
<p>一般来说，<strong>urlopen</strong>函数会出现两种异常</p>
<ul>
<li>网页在服务器上不存在，程序会返回<strong>HTTP</strong> 错误</li>
<li>服务器不存在，<strong>url</strong>会返回一个<strong>None</strong>对象</li>
</ul>
<p>对于以上两种情况的处理如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">try:
    html = urlopen("https://pythonscrapingthisurldoesnotexist.com")
except HTTPError as e:
    print("The server returned an HTTP error")
except URLError as e:
    print("The server could not be found!")
else:
    print(html.read())

if html is None:
    print('URL is not found')
else:
    # 程序继续<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果网页上的内容不像我们期待那样，没法读取所输入的标签，<strong>BeautifulSoup</strong>也会返回一个<strong>None</strong>对象，当调用此对象的子标签时，就会出现<strong>AttributeError</strong>，所以最好的做法是对读取的标签进行检测：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">try:
	badContent = bsObj.nonExistingTag.anotherTag
except AttributeError as e:
 	print("Tag was not found")
else:
 	if badContent == None:
 		print ("Tag was not found")
 	else:
 		print(badContent)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from urllib.error import HTTPError
from bs4 import BeautifulSoup

def getTitle(url):
 	try:
 		html = urlopen(url)
 	except HTTPError as e:
 		return None
        
 	try:
 		bsObj = BeautifulSoup(html.read())
 		title = bsObj.body.h1
 	except AttributeError as e:
 		return None
	return title

title = getTitle("http://www.pythonscraping.com/pages/page1.html")

if title == None:
 	print("Title could not be found")
else:
 	print(title)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="chapter-2-复杂html解析">Chapter 2 复杂HTML解析</h1>
<p><strong>Cascading Style Sheet，CSS</strong> 层叠样式表</p>
<p><strong>CSS</strong>可以让<strong>html</strong>的元素呈现差异化，使那些具有完全相同相同修饰的元素具有不同的形式</p>
<pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>span</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>red<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>span</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>span</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">'</span>green<span class="token punctuation">'</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>span</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="beautifulsoup-1">1 BeautifulSoup</h2>
<p>通过<strong>BeautifulSoup</strong>建立的对象<strong>bsObj</strong>，可以通过<strong>findAll</strong>函数进行批量抽取</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')
bs = BeautifulSoup(html, "html.parser")

nameList = bs.findAll('span', {'class': 'green'})
for name in nameList:
    print(name.get_text())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>get_text</strong>函数可以将源码中的超链接、标签、段落全部去掉，只剩下文本内容</p>
<h3 id="find-和-findall">find() 和 findAll()</h3>
<ul>
<li><strong>findAll(tag, attributes, recursive, text, limit, keywords)</strong></li>
<li><strong>find(tag, attributes, recursive, text, keywords)</strong></li>
</ul>
<p><strong>tag：</strong>一个或多个标签名称，<strong>{“h1”，“h2”，“h3”}</strong></p>
<p><strong>attributes：</strong> 用一个python字典封装一个标签的若干属性和对应的属性， <strong>("span", {"class":{"green", "red"}})</strong></p>
<p><strong>recursive：</strong> 布尔变量；默认值为<strong>True</strong></p>
<ul>
<li><strong>True：</strong> 搜索标签参数的所有子标签</li>
<li><strong>False：</strong> 只查找文档标签的第一级</li>
</ul>
<p><strong>text：</strong> 用标签的文本内容去匹配而不是用标签属性</p>
<p><strong>limit：</strong> 范围限制，<strong>find</strong>相当于<strong>findAll(limit=1)</strong></p>
<p><strong>keyword：</strong> 可以选择那些指定属性的标签</p>
<h3 id="beautifulsoup中的对象">BeautifulSoup中的对象</h3>
<ul>
<li><strong>BeautifulSoup</strong>对象，使用<strong>BeautifulSoup</strong>模块转化而成的对象，通常写作<strong>bsObj</strong></li>
<li>标签<strong>Tag</strong> 对象，通过<strong>find</strong>和<strong>findAll</strong>函数获取的对象，例<strong>bsObj.div.h1</strong></li>
<li><strong>NavigableString</strong> 对象，表示标签中的文字，而不是标签</li>
<li><strong>Comment</strong> 对象，用来查找<strong>HTML</strong>文档的注释标签</li>
</ul>
<h3 id="导航树">导航树</h3>
<p><strong>HTML</strong>都可以被映射成为一棵树：</p>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210830083717460.png" alt="image-20210830083717460"><figcaption aria-hidden="true">image-20210830083717460</figcaption>
</figure>
<h4 id="子标签和其他后代标签的处理方式">子标签和其他后代标签的处理方式</h4>
<p>子标签是父标签的下一代，而后代标签则是父标签的所有后代</p>
<p>一般在<strong>BeautifulSoup</strong>中<strong>find</strong>是找到父标签中出现的第一个标签，而<strong>findAll</strong>函则是在父标签中的所有后代标签中寻找符合条件的标签</p>
<p>如果只想找出子标签，可以使用<strong>.children</strong>标签</p>
<p>如果想在所有的后代标签中寻找，可以使用<strong>.descendants</strong>标签</p>
<h4 id="兄弟标签的处理方式">兄弟标签的处理方式</h4>
<p><strong>next_siblings()</strong></p>
<ul>
<li>寻找的对象不能获取，因为兄弟标签不会包括对象本身，只能调用与对象本身平行的兄弟标签</li>
<li>兄弟标签只能获取在对象标签本身后面的标签，平行与对象标签但是位于对象标签的前方的标签不能获取</li>
</ul>
<h4 id="父标签的处理方式">父标签的处理方式</h4>
<p><strong>parent()</strong> 可以访问当前标签的父标签</p>
<p><strong>previous_siblings()</strong> 可以访问当前标签的前一个兄弟标签</p>
<h2 id="正则表达式">2 正则表达式</h2>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210830090555285.png" alt="image-20210830090555285"><figcaption aria-hidden="true">image-20210830090555285</figcaption>
</figure>
<h2 id="beautifulsoup中的正则表达式">3 BeautifulSoup中的正则表达式</h2>
<p>抓取图片</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
import re

html = urlopen('http://www.pythonscraping.com/pages/page3.html')
bs = BeautifulSoup(html, 'html.parser')
images = bs.find_all('img', {'src':re.compile('\.\.\/img\/gifts/img.*\.jpg')})
for image in images: 
    print(image['src'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>src</strong>代表图片的路径属性</p>
<h2 id="获取属性">4 获取属性</h2>
<p>使用 <strong>attrs()</strong> 可以获取标签的全部属性</p>
<p><strong>myTag.attrs</strong></p>
<h2 id="lambda表达式">5 Lambda表达式</h2>
<p><strong>Lambda</strong>本质是一个函数，可以作为其他函数的变量使用</p>
<p><strong>f(g(x), h(x))</strong></p>
<p>获取具有两个属性的标签</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">bs.find_all(lambda tag: len(tag.attrs) == 2)
bs.find_all(lambda tag: tag.get_text() == 'Or maybe he\'s only resting?')
bs.find_all('', text='Or maybe he\'s only resting?')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h1 id="chapter-3-开始采集">Chapter 3 开始采集</h1>
<p>网络爬虫：沿着网络爬行</p>
<h2 id="遍历单个域名">1 遍历单个域名</h2>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup 

html = urlopen('http://en.wikipedia.org/wiki/Kevin_Bacon')
bs = BeautifulSoup(html, 'html.parser')
for link in bs.find_all('a'):
    if 'href' in link.attrs:
        print(link.attrs['href'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>bs.find_all('a')</strong></p>
<p>&lt;a&gt; 标签用来定义超链接</p>
<p>在<strong>Wiki</strong>中指向词条页面的链接，具有以下三个特点：</p>
<ul>
<li>都在<strong>id</strong>是<strong>bodyContent</strong>的<strong>div</strong>标签中</li>
<li><strong>URL</strong>链接不包含分号</li>
<li><strong>URL</strong>都以 <strong>/wiki/</strong> 开头</li>
</ul>
<p>随机爬行，直到网页上无其他符合条件的连接</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
import datetime
import random
import re

random.seed(datetime.datetime.now())
def getLinks(articleUrl):
    html = urlopen('http://en.wikipedia.org{}'.format(articleUrl))
    bs = BeautifulSoup(html, 'html.parser')
    return bs.find('div', {'id':'bodyContent'}).find_all('a', href=re.compile('^(/wiki/)((?!:).)*$'))

links = getLinks('/wiki/Kevin_Bacon')
while len(links) &gt; 0:
    newArticle = links[random.randint(0, len(links)-1)].attrs['href']
    print(newArticle)
    links = getLinks(newArticle)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="采集整个网站">2 采集整个网站</h2>
<p>使用数据库来储存采集到的资源</p>
<ul>
<li>浅网：互联网引擎上可以抓取到的部分</li>
<li>深网：互联网无法抓取</li>
<li>暗网：使用<strong>Tor</strong>客户端，带有运行在<strong>HTTP</strong>之上的新协议，提供一个信息交换的安全隧道</li>
</ul>
<h3 id="采集整个网站的用途">采集整个网站的用途</h3>
<ul>
<li>生成网站地图</li>
<li>收集数据</li>
</ul>
<h3 id="链接去重">链接去重</h3>
<p>在代码运行时，把已发现的所有链接都放在一起，并保存在方便查询的列表中（<strong>python</strong>的<strong>set</strong>集合）</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">def getLinks(pageUrl):
    global pages
    html = urlopen('http://en.wikipedia.org{}'.format(pageUrl))
    bs = BeautifulSoup(html, 'html.parser')
    for link in bs.find_all('a', href=re.compile('^(/wiki/)')):
        if 'href' in link.attrs:
            if link.attrs['href'] not in pages:
                #We have encountered a new page
                newPage = link.attrs['href']
                print(newPage)
                pages.add(newPage)
                getLinks(newPage)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="section"></h5>
<h3 id="收集整个网站数据">收集整个网站数据</h3>
<ul>
<li>所有的标题都是在<strong>h1 -&gt; span</strong>标签中，而且页面只有一个<strong>h1</strong>标签</li>
<li>所有的正文文字都是在<strong>div#bodyContent</strong>标签中，如果进一步获取文字，可使用<strong>div#mw-content-text -&gt; p</strong></li>
<li>编辑链接只出现在词条页面上，其都位于<strong>li#ca-edit</strong>标签的<strong>li#ca-edit -&gt; span -&gt; a</strong> 中</li>
</ul>
<p>爬虫与数据采集的组合程序</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
import re

pages = set()
def getLinks(pageUrl):
    global pages
    html = urlopen('http://en.wikipedia.org{}'.format(pageUrl))
    bs = BeautifulSoup(html, 'html.parser')
    try:
        print(bs.h1.get_text())
        print(bs.find(id ='mw-content-text').find_all('p')[0])
        print(bs.find(id='ca-edit').find('span').find('a').attrs['href'])
    except AttributeError:
        print('This page is missing something! Continuing.')
    
    for link in bs.find_all('a', href=re.compile('^(/wiki/)')):
        if 'href' in link.attrs:
            if link.attrs['href'] not in pages:
                #We have encountered a new page
                newPage = link.attrs['href']
                print('-'*20)
                print(newPage)
                pages.add(newPage)
                getLinks(newPage)
getLinks('') <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="通过互联网采集">3 通过互联网采集</h2>
<h3 id="urlparse-模块介绍">urlparse 模块介绍</h3>
<p><strong>urlparse</strong> 模块主要用于解析<strong>url</strong>中的参数，对<strong>url</strong>按照一定格式进行拆分或拼接</p>
<ul>
<li><strong>urlparse.urlparse</strong></li>
</ul>
<p>该函数可将<strong>url</strong>划分为六个部分，返回一个包含6个字符串项目的元组：协议、位置、路径、参数、查询、片段</p>
<p><strong>parseResult(scheme=, netloc=, path=, params=, quety=, fragment=)</strong></p>
<p>其中 <strong>scheme</strong> 是协议 <strong>netloc</strong> 是域名服务器 path 相对路径 <strong>params</strong>是参数，<strong>query</strong>是查询的条件</p>
<ul>
<li><strong>urlparse.urlsplit</strong></li>
</ul>
<p>和<strong>urlparse</strong>函数类似，此函数将<strong>url</strong>分为五个部分：协议、位置、路径、查询、片段</p>
<ul>
<li><strong>urlparse.urljoin</strong></li>
</ul>
<p>将相对的地址组合成一个url，对于输入没有限制，开头必须是http://，否则将不组合前面。</p>
<h3 id="采集外链流程图">采集外链流程图</h3>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210902095353833.png" alt="image-20210902095353833"><figcaption aria-hidden="true">image-20210902095353833</figcaption>
</figure>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210902095535033.png" alt="image-20210902095535033"><figcaption aria-hidden="true">image-20210902095535033</figcaption>
</figure>
<h2 id="用scrapy采集">4 用Scrapy采集</h2>
<p>创建新的<strong>Scrapy</strong>项目</p>
<p><strong>$scrapy startproject wikiSpider</strong></p>
<p>创建后文件目录结构：</p>
<ul>
<li><strong>scrapy.cfg</strong></li>
<li><strong>wikiSpider</strong>
<ul>
<li>__ <strong>init</strong> __.<strong>py</strong></li>
<li><strong>items.py</strong></li>
<li><strong>pipeline.py</strong></li>
<li><strong>setting.py</strong></li>
<li><strong>spiders</strong>
<ul>
<li>__ <strong>init</strong> __.<strong>py</strong></li>
</ul></li>
</ul></li>
</ul>
<p><strong>Scrapy</strong>中每个<strong>Itcm</strong>（条目）对象表示网站上的一个页面</p>
<p>你可以在 <strong>wikiSpider</strong> 主目录中用如下命令运行 <strong>ArticleSpider</strong>：</p>
<p><strong>$ scrapy crawl article</strong></p>
<h1 id="chapter-4-使用api">Chapter 4 使用API</h1>
<p>编程接口 <strong>Application Programming Interface</strong></p>
<p>为不同的应用提供了方便友好的接口</p>
<h2 id="api-概述">1 API 概述</h2>
<p><strong>EPSN</strong>: 提供了运动员信息、比赛分数</p>
<p><strong>Google</strong>开发者社区 https://console.developers.google.com/ : 提供了获取语言翻译、分析、地理位置等信息</p>
<p><strong>API</strong> 的请求使用需要非常严谨的语法，而且<strong>API</strong>使用<strong>JSON</strong>或者<strong>XML</strong>格式表示数据，而不是<strong>HTML</strong></p>
<h2 id="api-通用规则">2 API 通用规则</h2>
<h3 id="方法">方法</h3>
<p>利用<strong>HTTP</strong> 从网络服务获取信息的方式有四种：</p>
<ul>
<li><strong>GET</strong></li>
<li><strong>POST</strong></li>
<li><strong>PUT</strong></li>
<li><strong>DELETE</strong></li>
</ul>
<p><strong>GET</strong>在浏览器中输入网址浏览网站做出的响应</p>
<p><strong>POST</strong>填写表单或提交信息到网络服务器后端程序时需要做的事情</p>
<p><strong>PUT</strong>更新一个对象的信息</p>
<p><strong>DELETE</strong>删除一个对象</p>
<h3 id="验证">验证</h3>
<p>通常 API 验证的方法都是用类似令牌 <strong>（token）</strong> 的方式调用，每次 <strong>API</strong> 调用都会把令牌传递到服务器上。这种令牌要么是用户注册的时候分配给用户，要么就是在用户调用的时候才提供，可能是长期固定的值，也可能是频繁变化的，通过服务器对用户名和密码的组合处理后生成。</p>
<p>令牌除了在 <strong>URL</strong> 链接中传递，还会通过请求头里的 <strong>cookie</strong> 把用户信息传递给服务器。使用<strong>urllib</strong>进行<strong>token</strong>的传递</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">token = "&lt;your api token&gt;"
webRequest = urllib.request.Request("http://myapi.com", headers={"token":token})
html = urlopen(webRequest)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="服务器响应">3 服务器响应</h2>
<p><strong>JSON</strong>文件比<strong>XML</strong>文件具有更小的体积，其次因为网络技术的进步，许多服务器技术处理<strong>JSON</strong>比处理<strong>XML</strong>简单。</p>
<h3 id="api调用">API调用</h3>
<p>当使用<strong>GET</strong>请求获取数据时，可以使用查询参数作为过滤器或附加请求</p>
<p>也可通过<strong>URL</strong>的路径指定<strong>API</strong>的版本、数据格式以及其他属性</p>
<p>还有一些<strong>API</strong>可通过请求参数的形式指定数据格式和<strong>API</strong>版本</p>
<h2 id="echo-nest">4 Echo Nest</h2>
<p><strong>The Echo Nest</strong> 音乐数据网站 3 是一个用网络爬虫建立的超级给力的企业级案例</p>
<h2 id="twitter-api">5 Twitter API</h2>
<h2 id="google-api">6 Google API</h2>
<p>可以查看<strong>google</strong>的帮助文档</p>
<h2 id="结合api及网络数据采集">7 结合API及网络数据采集</h2>
<h1 id="chapter-5-存储数据">Chapter 5 存储数据</h1>
<h5 id="需要将数据储存起来分析第五章会介绍三种数据管理方法">需要将数据储存起来分析，第五章会介绍三种数据管理方法</h5>
<h2 id="媒体文件">1 媒体文件</h2>
<p>存储媒体文件有两种主要形式：</p>
<ul>
<li>获取存储文件的<strong>URL</strong></li>
<li>直接将源文件下载下来</li>
</ul>
<p>通过<strong>URL</strong>链接直接引用的优点：</p>
<ul>
<li>运行的更快，耗费流量更少</li>
<li>节省储存空间</li>
<li>代码更容易写</li>
<li>降低目标主机服务器的负载</li>
</ul>
<p>缺点：</p>
<ul>
<li>内嵌在自己网站或应用中的外站<strong>URL</strong>链接被称为<strong>盗链</strong></li>
<li><strong>盗链</strong>非常容易改变</li>
</ul>
<p>通过<strong>python</strong>中<strong>urllib.resquest.urlretrieve</strong>模块可以根据文件的<strong>URL</strong>下载文件：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlretrieve
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://www.pythonscraping.com')
bs = BeautifulSoup(html, 'html.parser')
imageLocation = bs.find('a', {'id': 'logo'}).find('img')['src']
urlretrieve (imageLocation, 'logo.jpg')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="将数据储存在csv文件">2 将数据储存在CSV文件</h2>
<p>网络数据采集一个常用功能就是获取<strong>HTML</strong>表格写入<strong>CSV</strong>文件</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import csv
from urllib.request import urlopen
from bs4 import BeautifulSoup

html = urlopen('http://en.wikipedia.org/wiki/Comparison_of_text_editors')
bs = BeautifulSoup(html, 'html.parser')
# The main comparison table is currently the first table on the page
table = bs.findAll('table',{'class':'wikitable'})[0]
rows = table.findAll('tr')

csvFile = open('editors.csv', 'wt+')
writer = csv.writer(csvFile)
try:
    for row in rows:
        csvRow = []
        for cell in row.findAll(['td', 'th']):
            csvRow.append(cell.get_text())
        writer.writerow(csvRow)
finally:
    csvFile.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="mysql">3 MySQL</h2>
<p>关系型数据</p>
<h3 id="安装mysql">安装<strong>MySQL</strong></h3>
<p><strong>Windows</strong>安装工具http://dev.mysql.com/downloads/windows/installer/</p>
<h3 id="mysql语法"><strong>MySQL</strong>语法</h3>
<p>首次登陆<strong>MySQL</strong>，创建数据库：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">create database scraping;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>MySQL</strong>的语法必须带有分号</p>
<p>指定某个特定的数据库使用：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">USE scraping;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>创建一个表用来储存采集的网页：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">&gt;CREATE TABLE pages (id BIGINT(7) NOT NULL AUTO_INCREMENT, title VARCHAR(200),
content VARCHAR(10000), created TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY
(id));<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210905100759435.png" alt="image-20210905100759435"><figcaption aria-hidden="true">image-20210905100759435</figcaption>
</figure>
<p>在实际存储的过程中只需要存储<strong>title</strong>与<strong>content</strong>两个字段，因为<strong>id</strong>是递增的，而<strong>created</strong>会自动加入时间戳</p>
<p>选择<strong>id</strong>为2的数据：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">select * from pages where id = 2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>选择<strong>title</strong>为<strong>“test”</strong>的数据：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">select * from pages where title like "%test%";<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>返回数据的特定字段</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">select id content from pages where content like "%page content%";<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>delete</strong>语法与<strong>select</strong>语法类似</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">delete from pages id = 1;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>update</strong>语法</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">UPDATE pages SET title="A new title", content="Some new content" WHERE id=2;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="与python结合">与python结合</h3>
<p>安装<strong>python</strong>模块：<strong>pymysql</strong></p>
<p>使数据库支持<strong>Unicode</strong>字符串：</p>
<pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">ALTER DATABASE scraping CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;ALTER TABLE pages CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;ALTER TABLE pages CHANGE title title VARCHAR(200) CHARACTER SET utf8mb4 COLLATEutf8mb4_unicode_ci;ALTER TABLE pages CHANGE content content VARCHAR(10000) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="数据库技术与最佳实践">数据库技术与最佳实践</h3>
<h2 id="email">4 Email</h2>
<p>邮件与网页不同，网页是通过<strong>HTTP</strong>协议传输的，邮件是通过<strong>SMTP</strong>协议传输的</p>
<p>使用<strong>python</strong>发送邮件：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import smtplibfrom email.mime.text import MIMETextmsg = MIMEText('The body of the email is here')msg['Subject'] = 'An Email Alert'msg['From'] = 'ryan@pythonscraping.com'msg['To'] = 'webmaster@pythonscraping.com's = smtplib.SMTP('localhost')s.send_message(msg)s.quit()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h1 id="chapter-6-读取文档">Chapter 6 读取文档</h1>
<p>重点介绍文档处理的相关内容，包扩：</p>
<ul>
<li>将文件下载到文件夹</li>
<li>读取文档提取数据</li>
<li>文档的不同编码类型</li>
</ul>
<h2 id="文档编码">1 文档编码</h2>
<p>文档编码就是文件读取的规则</p>
<p>从最底层的角度来看，所有的文档都是由0和1编码而成的。</p>
<p>体积缩减或者数据压缩算法都是根据编码算法定义：每个字符多少位、每个像素的颜色值用多少位，例如<strong>PNG</strong>图像编码格式就是一种无损压缩的位图图形格式</p>
<h2 id="纯文本">2 纯文本</h2>
<p>对于简单的纯文本文件，可以直接读取页面内容</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen

textPage = urlopen(url)
print(textPage.read())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>缺点是不能使用<strong>html</strong>中的标签去定义需要的文字</p>
<h3 id="文本编码和全球互联网">文本编码和全球互联网</h3>
<h4 id="编码类型简介">编码类型简介</h4>
<p><strong>UTF-8</strong>：</p>
<p><strong>UTF-8</strong> 的每个字符开头有一个标记表示“这个字符只用一个字节”或“那个字符需要用两个字节”，一个字符最多可以是四个字节。由于这四个字节里还包含一部分设置信息，用来决定多少字节用做字符编码，所以全部的 32 位（32 位 =4 字节 ×8 位 / 字 节）并不会都用，其实最多使用 21 位，也就是总共 2 097 152 种可能里面可以有 1 114 112 个字符</p>
<p><strong>ASCII</strong>:</p>
<p><strong>ASCII</strong> 是 20 世纪 60 年代开始使用的文字编码标准，每个字符 7 位，一共 27 ，即 128 个字 符。</p>
<h4 id="编码进行">编码进行</h4>
<p>将读取到的字符串使用<strong>UTF-8</strong>输出</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">print(str(textPage.read(), 'utf-8'))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
在处理<strong>HTML</strong>网页时，大多是网站都会在**

<p>**部分显示页面使用的编码格式</p>
**
<meta charset="utf-8">
<p>**</p>
<h2 id="csv">3 CSV</h2>
<h3 id="读取csv文件">读取CSV文件</h3>
<p>一共有三种方法可以读取使用<strong>CSV</strong>文件：</p>
<ul>
<li>手动下载<strong>CSV</strong>文件，然后用<strong>python</strong>定义文件位置</li>
<li>使用<strong>Python</strong>下载<strong>CSV</strong>文件，之后再将源文件删除</li>
<li>直接将网上的<strong>CSV</strong>文件读成字符串，然后转化为一个<strong>StringIO</strong>对象，使它具有文件属性</li>
</ul>
<p>一般使用第三种方法是最节省空间</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from io import StringIO
import csv

data = urlopen('http://pythonscraping.com/files/MontyPythonAlbums.csv').read().decode('ascii', 'ignore')
dataFile = StringIO(data)
csvReader = csv.reader(dataFile)

for row in csvReader:
    print(row)
    print("The album \""+row[0]+"\" was released in "+str(row[1]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="csv.dictreader"><strong>csv.DictReader</strong></h4>
<p><strong>csv.DictReader</strong>会将<strong>CSV</strong>文件的每一行转换为<strong>Python</strong>的字典对象返回，而不是列表对象，此时<strong>CSV</strong>文件中的字段列表则作为字典中的键</p>
<h2 id="pdf">4 PDF</h2>
<p>（https://pypi.python.org/pypi/pdfminer3k）</p>
<h2 id="word和.docx">5 Word和.docx</h2>
<h1 id="chapter-7-数据清洗">Chapter 7 数据清洗</h1>
<p>介绍一些工具和技术，通过改变代码的编写方式，帮你 从源头控制数据零乱的问题，并且对已经进入数据库的数据进行清洗</p>
<h2 id="编写代码清洗数据">1 编写代码清洗数据</h2>
<p><strong>n-gram</strong>：表示文字或语言中n个连续的单词组成的序列</p>
<p>如何获得格式合理的<strong>n-gram</strong></p>
<p>通过建立简单的数据清洗函数</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">def cleanInput(input):
    input = re.sub('\n+', " ", input)
    input = re.sub('\[[0-9]*\]', "", input)
    input = re.sub(' +', " ", input)
    input = bytes(input, "UTF-8")
    input = input.decode("ascii", "ignore")
    cleanInput = []
    input = input.split(' ')
    for item in input:
        item = item.strip(string.punctuation)
        if len(item) &gt; 1 or (item.lower() == 'a' or item.lower() == 'i'):
            cleanInput.append(item)
    return cleanInput<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="数据标准化">数据标准化</h3>
<p>自动对输入的信息进行清洗，去掉不正确的内容，按照标准格式进行输出</p>
<p>在<strong>Python</strong>中的<strong>collections</strong>库中有一个有序字典<strong>OrderedDict</strong>可以解决这个问题</p>
<h2 id="数据存储后再进行清洗">2 数据存储后再进行清洗</h2>
<h3 id="openrefine">OpenRefine</h3>
<h1 id="chapter-8-自然语言处理">Chapter 8 自然语言处理</h1>
<h2 id="概括数据">1 概括数据</h2>
<p>在上一章中，将文本内容分解成<strong>n-gram</strong>模型，从基本功能上来说，这个集合可以确定这段文字中最常用的单词和短语</p>
<p>在将文本内容排序之后，可以使用<strong>python</strong>中的<strong>operator</strong>模块对<strong>n-gram</strong>进行排序</p>
<p>除此之外，可以提取原文中那些最常用的短语周围的句子，对原文进行概括</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup

import re
import string
import operator

def cleanInput(input):
    input = re.sub("\n+", " ", input).lower()
    input = re.sub('\[[0-9]*\]', "", input)
    input = re.sub(' +', " ", input)
    input = bytes(input, 'UTF-8')
    input = input.decode("ascii", "ignore")
    cleanInput = []

    input = input.split(" ")

    for item in input:
        item = item.strip(string.punctuation)
        if len(item) &gt; 1 or (item.lower() == 'a' or item.lower() == 'i'):
            cleanInput.append(item)
    
    return cleanInput

def isCommon(ngram):
    commonWords = ["the", "be", "and", "of", "a", "in", "to", "have", "it",
                    "i", "that", "for", "you", "he", "with", "on", "do", "say", "this",
                    "they", "is", "an", "at", "but","we", "his", "from", "that", "not",
                    "by", "she", "or", "as", "what", "go", "their","can", "who", "get",
                    "if", "would", "her", "all", "my", "make", "about", "know", "will",
                    "as", "up", "one", "time", "has", "been", "there", "year", "so",
                    "think", "when", "which", "them", "some", "me", "people", "take",
                    "out", "into", "just", "see", "him", "your", "come", "could", "now",
                    "than", "like", "other", "how", "then", "its", "our", "two", "more",
                    "these", "want", "way", "look", "first", "also", "new", "because",
                    "day", "more", "use", "no", "man", "find", "here", "thing", "give",
                    "many", "well"]
    for word in ngram:
        if word in commonWords:
            return True
    return False

def ngrams(input, n):
    input = cleanInput(input)
    output = {}
    for i in range(len(input)-n+1):
        ngramTemp = " ".join(input[i:i+n])
        if ngramTemp not in output:
            output[ngramTemp] = 0
        output[ngramTemp] += 1
    
    return output

content = str(urlopen("http://pythonscraping.com/files/inaugurationSpeech.txt").read(),'utf-8')
ngrams = ngrams(content, 2)
sortedNGrams = sorted(ngrams.items(), key = operator.itemgetter(1), reverse=True)
for ngram in sortedNGrams:
    
    if not isCommon(ngram[0].split(" ")):
        print(ngram, end=' ')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="马尔可夫模型">2 马尔可夫模型</h2>
<p>马尔可夫文字生成器（<strong>Markov text generator</strong>）</p>
<p>这些文字生成器都是基于分析大量随机事件的马尔可夫模型，随机事件的特点是一个离散事件发生之后，另一个离散事件在前一个事件发生的条件下以一定概率发生</p>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210907094611686.png" alt="image-20210907094611686"><figcaption aria-hidden="true">image-20210907094611686</figcaption>
</figure>
<p>此系统具有以下特点：</p>
<ul>
<li>任何一个节点引出的可能性的总和必须是100%</li>
<li>只有当前节点会影响后一天的状态</li>
<li>每个节点接受可能性不同，接受的可能性越小到达此点的可能性越小</li>
</ul>
<p><strong>Google 的 page rank 算法</strong></p>
<p>基于马尔可夫模型， 把网站作为节点，入站和出站链接作为节点之间的连线，而连接某个节点的可能性表示一个网站的相对关注度。</p>
<h3 id="维基百科六度分割">维基百科六度分割</h3>
<p>网站之间的连接相当于一个有向图问题</p>
<p>寻找最短路径的方法：<strong>广度优先搜索</strong></p>
<h2 id="自然语言工具包">3 自然语言工具包</h2>
<p><strong>Natural Language Toolkit，NLTK</strong></p>
<p>其用来识别和标记英语文本中每个词的属性</p>
<h3 id="安装与设置">安装与设置</h3>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import nltk
nltk,download()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>打开<strong>NLTK</strong>的下载器</p>
<h3 id="使用nltk做统计分析">使用NLTK做统计分析</h3>
<p><strong>NLTK</strong>的统计对象：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from nltk import word_tokenize
from nltk import Text
tokens = word_tokenize("Here is some not very interesting text")
text = Text(tokens)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>NLTK</strong>频率分布对象<strong>FreqDist</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from nltk import FreqDist
fdist = FreqDist(text6)
fdist.most_common(10)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong>2-ngram</strong>模型：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from nltk import bigrams
bigrams = bigrams(text6)
bigramsDist = FreqDist(bigrams)
bigramsDist[("Sir", "Robin")]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="nltk做词性分析">NLTK做词性分析</h3>
<p>Penn Treebank 语义标记</p>
<p><img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210907110634539.png" alt="image-20210907110634539" style="zoom:50%;"></p>
<p><img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210907110702958.png" alt="image-20210907110702958" style="zoom:50%;"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from nltk import pos_tag
pos_tag(text)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h1 id="chapter-9-穿越网页表单与登录窗口进行采集">Chapter 9 穿越网页表单与登录窗口进行采集</h1>
<p>通过<strong>POST</strong>请求网页数据</p>
<h2 id="python-requests-库">1 python requests 库</h2>
<p><strong>Requests</strong>库就是一个擅长处理那些复杂的<strong>HTTP</strong>请求、<strong>cookies</strong>、header等内容的<strong>python</strong>第三方库</p>
<p>因为python的标准库 <strong>urllib2</strong> <strong>API</strong>不太行</p>
<h2 id="提交一个基本的表单">2 提交一个基本的表单</h2>
<p>网页表单：大多数由一些<strong>HTML</strong>字段、一个提交按钮、一个表单处理完之后跳转的执行结果页面构成。表单的目的只是帮助网站的访问者发送合理的请求，向服务器请求没有出现的页面</p>
<p>大多数主流网站都会在<strong>robots.txt</strong>文件里注明禁止爬虫接入的登录表单</p>
<p>表单的真实行为都发生在<strong>processing.php</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
params = {'firstname': 'Ryan', 'lastname': 'Mitchell'}
r = requests.post("http://pythonscraping.com/files/processing.php", data=params)
print(r.text)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="单选按钮复选框和其他输入">3 单选按钮、复选框和其他输入</h2>
<p>字段名称和值是用<strong>POST</strong>进行请求的最重要的两个方面的值</p>
<p>字段名称：可以通过查找源码寻找<strong>name</strong>属性轻易获取</p>
<p>字段的值：直接看网站的<strong>URL</strong>连接</p>
<h2 id="提交文件和图像">4 提交文件和图像</h2>
<p>直接提交，与提交文字没有区别，因为<strong>request.post</strong>有一个<strong>type</strong>选项为<strong>file</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
files = {'uploadFile': open('../files/Python-logo.png', 'rb')}
r = requests.post("http://pythonscraping.com/pages/processing2.php", files=files)
print(r.text)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="处理登录和cookie">5 处理登录和cookie</h2>
<p>大多数新型网站采用<strong>cookie</strong>跟踪用户是否登录的状态信息</p>
<p>一旦网站验证了你的登录权证，它就会将它们保存在你的浏览器的 cookie 中，里面通常包含一个服务器生成的令牌、登录有效时限和状态跟踪信息。网站会把这个 <strong>cookie</strong> 当作信息验证的证据，在你浏览网站的每个页面时出示给服务器。</p>
<p>使用<strong>Requests</strong>库进行跟踪<strong>cookie</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
params = {'username': 'Ryan', 'password': 'password'}

r = requests.post("http://pythonscraping.com/pages/cookies/welcome.php", params)
print("Cookie is set to:")
print(r.cookies.get_dict())
print("-----------")
print("Going to profile page...")
r = requests.get("http://pythonscraping.com/pages/cookies/profile.php", cookies=r.cookies)
print(r.text)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>或者使用<strong>seesion</strong>函数，其能持续的跟踪会话信息，包括<strong>cookie</strong>、<strong>header</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
session = requests.Session()
params = {'username': 'username', 'password': 'password'}
s = session.post("http://pythonscraping.com/pages/cookies/welcome.php", params)
print("Cookie is set to:")
print(s.cookies.get_dict())
print("-----------")
print("Going to profile page...")
s = session.get("http://pythonscraping.com/pages/cookies/profile.php")
print(s.text)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="http基本接入认证">HTTP基本接入认证</h3>
<p>使用<strong>Requests.auth</strong>模块来处理<strong>HTTP</strong>认证：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">import requests
from requests.auth import AuthBase
from requests.auth import HTTPBasicAuth
auth = HTTPBasicAuth('ryan', 'password')
r = requests.post(url="http://pythonscraping.com/pages/auth/login.php", auth=auth)
print(r.text)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="chapter-10-采集javascript">Chapter 10 采集JavaScript</h1>
<p>通常在客户端的语言只有两种：</p>
<ul>
<li>ActionScript</li>
<li>JavaScript</li>
</ul>
<h2 id="javascript-简介">1 JavaScript 简介</h2>
<p><strong>JavaScript</strong> 是一种弱类型语言，其语法通常可以与 <strong>C++</strong> 和 Java 做对比。虽然语法中的一些元素，比如操作符、循环条件和数组，都与 <strong>C++</strong>、Java 语法很接近，但是 <strong>JavaScript</strong> 的弱类型和脚本形式被一些程序员看成是折磨人的怪兽。</p>
<pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript"><span class="token operator">&lt;</span>script<span class="token operator">&gt;</span>
<span class="token keyword">function</span> <span class="token function">fibonacci</span><span class="token punctuation">(</span><span class="token parameter">a<span class="token punctuation">,</span> b</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
 	<span class="token keyword">var</span> nextNum <span class="token operator">=</span> a <span class="token operator">+</span> b<span class="token punctuation">;</span>
 	console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span>nextNum<span class="token operator">+</span><span class="token string">" is in the Fibonacci sequence"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 	<span class="token keyword">if</span><span class="token punctuation">(</span>nextNum <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
 	<span class="token function">fibonacci</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> nextNum<span class="token punctuation">)</span><span class="token punctuation">;</span>
 	<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token function">fibonacci</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>script<span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意 <strong>JavaScript</strong> 里所有的变量都用 <strong>var</strong> 关键词字进行定义</p>
<p><strong>JavaScript</strong> 还有一个非常好的特性，就是把函数作为变量使用：</p>
<h3 id="常用的javascript库">常用的<strong>JavaScript</strong>库</h3>
<p>用 <strong>Python</strong> 执行 <strong>JavaScript</strong> 代码的效率非常低，既费时又费力，尤其是在处理规模较大的 <strong>JavaScript</strong> 代码时。</p>
<ul>
<li><strong>jQuery</strong></li>
<li><strong>Google Analytics</strong></li>
<li><strong>Google</strong>地图</li>
</ul>
<h2 id="ajax和动态html">2 Ajax和动态HTML</h2>
<p><strong>Ajax</strong> 其实并不是一门语言，而是用来完成网络任务（可以认为 它与网络数据采集差不多）的一系列技术。<strong>Ajax</strong> 全称是 <strong>Asynchronous</strong> <strong>JavaScript</strong> <strong>and</strong> <strong>XML</strong> （异步 <strong>JavaScript</strong> 和 <strong>XML</strong>），网站不需要使用单独的页面请求就可以和网络服务器进行交互 （收发信息）。</p>
<p>和 <strong>Ajax</strong> 一样，动态 <strong>HTML（dynamic HTML，DHTML）</strong>也是一系列用于解决网络问题的 技术集合。DHTML 是用客户端语言改变页面的 <strong>HTML</strong> 元素（HTML、CSS，或者二者皆 被改变）。比如，页面上的按钮只有当用户移动鼠标之后才出现，背景色可能每次点击都 会改变，或者用一个 <strong>Ajax</strong> 请求触发页面加载一段新内容。</p>
<p><strong>Python</strong> 解决这个问题只有两种途径：直接从 <strong>JavaScript</strong> 代码里采集内容，或者用 <strong>Python</strong> 的 第三方库运行 <strong>JavaScript</strong>，直接采集你在浏览器里看到的页面。</p>
<h3 id="在python中使用selenium执行javascript">在python中使用Selenium执行JavaScript</h3>
<p><strong>Selenium</strong> 可以让浏览器自动加载页面，获取需要的数据，甚至页面截屏，或者判断网站上某些动作是否发生。<strong>Selenium</strong>自己不带浏览器。必须结合第三方浏览器才能使用。</p>
<p><strong>PhantomJS</strong>（http://phantomjs.org/download.html）：此浏览器会把网站加载到内存并执行JavaScript，但是不会向用户展示网页的图形页面。将<strong>Selenium</strong>与<strong>PhantomJS</strong>结合就能运行一个强大的爬虫了</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from selenium import webdriver
import time
driver = webdriver.PhantomJS(executable_path='')
driver.get("http://pythonscraping.com/pages/javascript/ajaxDemo.html")
time.sleep(3)
print(driver.find_element_by_id('content').text)
driver.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用<strong>Selenium</strong>可以读取页面加载后三秒的图像</p>
<h2 id="处理重定向">3 处理重定向</h2>
<p>客户端重定向是在服务器将页面内容发送到浏览器之前，由浏览器执行 <strong>JavaScript</strong> 完成的页面跳转，而不是服务器完成的跳转。根据具体情况， 服务器端重定向一般都可以轻松地通过 Python 的 urllib 库解决</p>
<p>我们可以用一种智能的方法来检测客户端重定向是否完成，首先从页面开始加载时就“监视”<strong>DOM</strong> 中的一个元素，然后重复调用这个元素直到 <strong>Selenium</strong> 抛出一个 <strong>StaleElementReferenceException</strong> 异常；也就是说，元素不在页面的 <strong>DOM</strong> 里了，说明这时网站已经跳转</p>
<h1 id="chapter-11-图像识别与文字处理">Chapter 11 图像识别与文字处理</h1>
<p>主要搞定图像验证码，或者被做成图像的文字</p>
<h2 id="ocr库概述">1 OCR库概述</h2>
<h3 id="pillow">Pillow</h3>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">from PIL import Image, ImageFilter
kitten = Image.open("kitten.jpg")
blurryKitten = kitten.filter(ImageFilter.GaussianBlur)
blurryKitten.save("kitten_blurred.jpg")
blurryKitten.show(<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以利用<strong>Pillow</strong>进行图像预处理，此外<strong>Pillow</strong>还可以完成许多复杂的图像处理工作，详细可见<strong>Pillow</strong>文档：</p>
<p>http://pillow.readthedocs.org/</p>
<h3 id="tesseract">Tesseract</h3>
<p><strong>Tesseract</strong> 是目前公认最优秀、最精确的开源 <strong>OCR</strong> 系统</p>
<p><strong>Tesseract</strong> 是一个 Python 的命令行工具，不是通过 <strong>import</strong>语句导入的库。安装之后，要用 <strong>tesseract</strong> 命令在 <strong>Python</strong> 的外面运行</p>
<h3 id="安装tesseract">安装Tesseract</h3>
<p><strong>Windows</strong>: https://code.google.com/p/tesseract-ocr/downloads/list</p>
<h2 id="处理格式规范的文字">2 处理格式规范的文字</h2>
<p>清晰且没有背景色混乱的文字能使用<strong>Tesseract</strong>直接读取：</p>
<p>$tesseract text.tif textoutput | cat textoutput.txt</p>
<p>输出结果的第一行是 <strong>Tesseract</strong> 的版本信息，表明它正在运行，后面是图片识别结果 <strong>textoutput.txt</strong> 文件里的内容</p>
<p>如果文字带有模糊效果，且背景色为渐变色，那么<strong>Tesseract</strong>不能处理这种图片</p>
<p>遇到这类问题，需要采用python脚本对图片进行处理，通过<strong>Pillow</strong>库可以创建一个阈值过滤器去掉渐变背景色。</p>
<h3 id="从网站图片中抓取文字">从网站图片中抓取文字</h3>
<h2 id="读取验证码与训练tesseract">3 读取验证码与训练Tesseract</h2>
<p>使验证码让机器难以读懂：</p>
<ul>
<li>字母+数字</li>
<li>字母的倾斜程度会迷惑OCR软件</li>
<li>陌生的手写体</li>
</ul>
<h3 id="训练tesseract">训练<strong>Tesseract</strong></h3>
<p>在线工具：Tesseract OCR Chopper（http://pp19dd.com/tesseract-ocr-chopper/）</p>
<h2 id="获取验证码提交答案">4 获取验证码提交答案</h2>
<p>大多数网站生成的验证码图片都具有以下属性：</p>
<ul>
<li>它们是服务器端的程序动态生成的图片。验证码图片的 src 属性可能和普通图片不太一 样，但是可以和其他图片一样进行 下载和处理。</li>
<li>图片的答案存储在服务器端的数据库里。</li>
<li>很多验证码都有时间限制，如果你太长时间没解决就会失效。虽然这对网络机器人来说不是什么问题，但是如果你想保留验证码的答案一会儿再使用，或者想通过一些方法延长验证码的有效时限，可能很难成功。</li>
</ul>
<p>常用的处理方法就是，首先把验证码图片下载到硬盘里，清理干净，然后用 Tesseract 处理 图片，最后返回符合网站要求的识别结果。</p>
<h1 id="chapter-12-避开采集陷阱">Chapter 12 避开采集陷阱</h1>
<h2 id="道德规范">1 道德规范</h2>
<h2 id="让网络机器人看起来像人类用户">2 让网络机器人看起来像人类用户</h2>
<h3 id="修改请求头">修改请求头</h3>
<p><strong>requests</strong> 模块还可以设置请求头</p>
<p><strong>HTTP</strong> 的请求头是在你每次向网络服务器发送请求时，传递的一组属性和配置信息</p>
<p>以下七个字段被大多数浏览器应用</p>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210908203305001.png" alt="image-20210908203305001"><figcaption aria-hidden="true">image-20210908203305001</figcaption>
</figure>
<figure>
<img src="/2021/09/10/python-wang-luo-shu-ju-cai-ji/image-20210908203317436.png" alt="image-20210908203317436"><figcaption aria-hidden="true">image-20210908203317436</figcaption>
</figure>
<p>请求头会改变观看网络世界的方式，最重要的请求头就是<strong>User-Agent</strong>，将其设置为不容易引起怀疑的内容</p>
<h3 id="合理处理cookie">合理处理cookie</h3>
<h3 id="时间处理">时间处理</h3>
<p>尽量保证一次加载页面加载且数据请求最小化</p>
<p>如果条件允许，尽量为每个页面访问增加一点时间间隔</p>
<p>过高的采集速度会拖垮网站</p>
<h2 id="常见表单安全措施">3 常见表单安全措施</h2>
<p>网络机器人在网站上创建几千个垃圾账号，并给其他所有用户发送垃圾邮件</p>
<h3 id="隐含输入字段值">隐含输入字段值</h3>
<p>隐含的字段对浏览器可见对用户不可见，主要用于阻止爬虫自动提交表单</p>
<p>隐含字段阻止网络数据采集的方式主要有两种：</p>
<ul>
<li>第一种是表单上的一个字段可以用服务器生成的随机变量表示，绕开这个问题的最佳方法就是采集表单所在页面上的随机变量，然后再提交表单处理页面</li>
<li>第二种方式就是蜜罐，如果表单里包含一个具有普通名称的隐含字段（设置 蜜罐圈套），比如“用户名”（<strong>username</strong>）或“邮箱地址”（<strong>email</strong> <strong>address</strong>），设计不太好的网 络机器人往往不管这个字段是不是对用户可见，直接填写这个字段并向服务器提交，这样 就会中服务器的蜜罐圈套。服务器会把所有隐含字段的真实值（或者与表单提交页面的默 认值不同的值）都忽略，而且填写隐含字段的访问用户也可能被网站封杀。</li>
</ul>
<h3 id="避免蜜罐">避免蜜罐</h3>
<p>此字段直接就是不可见的，因为它不可显示到浏览器上，如果填写表单的时候填写了此字段，那么就判断你为机器人，提交无效</p>
<p>一共有三种方式对用户隐藏</p>
<ul>
<li>CSS属性设置为<strong>display：none</strong>，浏览器直接不可见</li>
<li>通过设置<strong>type</strong>字段为<strong>hidden</strong></li>
<li>将字段设置位移一段距离到屏幕显示范围以外，用户不可见</li>
</ul>
<h2 id="问题检查表">4 问题检查表</h2>
<ul>
<li>如果爬虫接受到的网络信息是空白的，可能是<strong>JavaScript</strong>的问题</li>
<li>在<strong>POST</strong>请求时，核对信息是否正确</li>
<li>如果有登录异常，检查cookie是否正确被调用</li>
<li><strong>HTTP</strong>错误或者<strong>403</strong>错误，你已被识别为机器人</li>
<li>确认你的爬虫速度不能特别快</li>
<li>修改请求头</li>
<li>确实没有访问任何人类无法访问的信息或者链接</li>
<li>联系网管</li>
</ul>
<h1 id="chapter-13-用爬虫测试网站">Chapter 13 用爬虫测试网站</h1>
<p>通过爬虫来完成网站的前端测试</p>
<h2 id="测试简介">1 测试简介</h2>
<h3 id="单元测试">单元测试</h3>
<ul>
<li>每个单元测试用于测试一个零件（<strong>component</strong>）功能的一个方面，通常一个零件的所有单元测试都集成在同一个类里</li>
<li>每个单元测试都可以完全独立的运行，不能对其他测试造成干扰</li>
<li>每个单元测试通常至少包含一个断言</li>
<li>单元测试与生产代码是分离的</li>
</ul>
<h2 id="python的单元测试">2 python的单元测试</h2>
<p><strong>unittest</strong>单元测试模块，继承<strong>unittest.TestCase</strong>类，就可以实现以下功能：</p>
<ul>
<li>为每个单元测试的开始和结束提供<strong>setUp</strong>与<strong>tearDown</strong>函数</li>
<li>提供不同类型的“断言”语句让测试成功或失败</li>
<li>把所有以<strong>test_</strong>开头的函数当作单元测试运行，忽略不带<strong>test_</strong>的函数</li>
</ul>
<p><strong>unittest</strong>类的<strong>setUpClass</strong>函数只在类初始化阶段运行一次，用来代替<strong>setUp</strong>用来省去不必要的页面加载</p>
<h2 id="selenium-单元测试">3 Selenium 单元测试</h2>
<p><strong>python</strong>单元测试与<strong>Selenium</strong>单元测试不同</p>
<p><strong>Selenium</strong>不要求单元测试必须是类的一个函数，它的<strong>断言</strong>语句不需要括号，测试通过也不会有提示，只有当测试失败时才会有信息提示</p>
<h2 id="python单元测试与selenium单元测试的选择">4 python单元测试与Selenium单元测试的选择</h2>
<p><strong>Python</strong> 的单元测试语法严谨冗长，更适合为大多数大型项目写测试，而 <strong>Selenium</strong> 的测试方 式灵活且功能强大，可以成为一些网站功能测试的首选。</p>
<p><strong>Selenium</strong> 可以轻易地获取网站的信息，而单元测试可以评估这些信 息是否满足通过测试的条件。因此，你没有理由拒绝把 <strong>Selenium</strong> 导入 <strong>Python</strong> 的单元测试， 两者组合是最佳拍档。</p>
<h1 id="chapter-14-远程采集">Chapter 14 远程采集</h1>
<h2 id="为什么要用远程服务器">1 为什么要用远程服务器</h2>
<ol type="1">
<li>避免IP地址被封杀</li>
<li>移植性和可扩展性</li>
</ol>
<h2 id="tor代理服务器">2 Tor代理服务器</h2>
<p>洋葱路由（<strong>The Onion Router</strong>）网络，常用缩写为 Tor，是一种 IP 地址匿名手段。</p>
<h2 id="远程主机">3 远程主机</h2>
<h2 id="其他资源">4 其他资源</h2>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">xxxxlc</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://xxxxlc.github.io/2021/09/10/python-wang-luo-shu-ju-cai-ji/">https://xxxxlc.github.io/2021/09/10/python-wang-luo-shu-ju-cai-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">xxxxlc</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/reading-note/">
                                    <span class="chip bg-color">reading note</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/09/14/typora-shu-xue-fu-hao/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="typora-数学符号">
                        
                        <span class="card-title">typora-数学符号</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-09-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            xxxxlc
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/08/03/matlab-yi-ci-xiu-gai-quan-bu-bian-liang-ming/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="MATLAB一次修改全部变量名">
                        
                        <span class="card-title">MATLAB一次修改全部变量名</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-08-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            xxxxlc
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/MATLAB/">
                        <span class="chip bg-color">MATLAB</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4, h5, h6'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5, h6').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2022</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">xxxxlc</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/xxxxlc" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:913847100@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=913847100" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 913847100" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":300,"height":600},"mobile":{"show":false},"rect":"opacity:0.7","log":false,"tagMode":false});</script></body>

</html>
